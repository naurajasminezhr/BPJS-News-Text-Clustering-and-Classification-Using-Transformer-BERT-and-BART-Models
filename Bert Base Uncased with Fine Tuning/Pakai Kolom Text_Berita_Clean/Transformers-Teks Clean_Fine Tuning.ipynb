{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Klasifikasi Teks Berita yang sudah di Preprocessing (Clean) Menggunakan Model BERT dengan Fine-Tuning\n","\n","Kode ini bertujuan untuk melakukan klasifikasi teks berita menggunakan model BERT yang telah dilatih sebelumnya"],"metadata":{"id":"z4zCLI_5A0g7"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","import torch\n","\n","# Load the dataset from Excel\n","file_path = 'data_ready_with_kategori.xlsx'\n","data = pd.read_excel(file_path)\n","\n","# Filter data to use the text_berita_clean column and ensure it's not empty\n","filtered_data = data[['text_berita_clean', 'Kategori']].dropna()\n","\n","# Map string categories to integers\n","filtered_data['Kategori'] = filtered_data['Kategori'].astype('category')\n","filtered_data['Kategori_encoded'] = filtered_data['Kategori'].cat.codes\n","\n","# Debug: Print category mapping\n","category_mapping = dict(enumerate(filtered_data['Kategori'].cat.categories))\n","print(\"Category Mapping:\", category_mapping)\n","\n","# Split the dataset into training and validation sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    filtered_data['text_berita_clean'],\n","    filtered_data['Kategori_encoded'],\n","    random_state=42,\n","    test_size=0.2\n",")\n","\n","# Load BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize input texts\n","train_encodings = tokenizer(list(train_texts), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n","val_encodings = tokenizer(list(val_texts), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n","\n","# Define PyTorch dataset class\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels.values  # Convert labels to NumPy array\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure label dtype is long\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create datasets\n","train_dataset = CustomDataset(train_encodings, train_labels)\n","val_dataset = CustomDataset(val_encodings, val_labels)\n","\n","# Fine-tune a pre-trained BERT model\n","num_labels = len(filtered_data['Kategori_encoded'].unique())  # Number of unique categories\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./test_trainer\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    report_to=\"none\"\n",")\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Save the fine-tuned model\n","output_dir = \"./fine_tuned_bert_text_berita_clean_model\"\n","model.save_pretrained(output_dir)\n","\n","print(f\"Fine-tuned model saved to {output_dir}\")\n","\n","# Save the mapping of categories to integers\n","print(\"Category Mapping:\", category_mapping)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"_QSQAqud834V","outputId":"fbcf688b-b65b-4d58-b7c4-b5fa860a6d8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Category Mapping: {0: 'Ekonomi', 1: 'Hukum', 2: 'Kesehatan', 3: 'Ketenagakerjaan', 4: 'Teknologi'}\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1803' max='1803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1803/1803 5:38:17, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.865100</td>\n","      <td>0.857305</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.773100</td>\n","      <td>0.789412</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.719500</td>\n","      <td>0.723584</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tuned model saved to ./fine_tuned_bert_text_berita_clean_model\n","Category Mapping: {0: 'Ekonomi', 1: 'Hukum', 2: 'Kesehatan', 3: 'Ketenagakerjaan', 4: 'Teknologi'}\n"]}]},{"cell_type":"markdown","source":["1. Pada epoch pertama, model menunjukkan nilai kehilangan yang relatif tinggi, tetapi validation loss sedikit lebih rendah daripada training loss. Ini menunjukkan bahwa model mulai belajar dari data pelatihan tetapi masih jauh dari optimal.\n","\n","2. Pada epoch kedua, baik training loss maupun validation loss mengalami penurunan, dengan training loss menurun lebih signifikan. Namun, validation loss meningkat sedikit, yang bisa menjadi indikasi awal dari potensi overfitting, di mana model terlalu cocok dengan data pelatihan.\n","\n","3. Pada epoch ketiga, training loss terus menurun, menunjukkan bahwa model semakin baik dalam memprediksi label pada data pelatihan. Validation loss juga menurun, yang menunjukkan bahwa model mampu generalisasi dengan baik pada data validasi.\n","\n","Secara keseluruhan, hasil fine-tuning ini menunjukkan bahwa model BERT berhasil dilatih dengan baik selama proses pelatihan. Penurunan konsisten pada training loss dan validation loss menunjukkan bahwa model belajar dari data dan tidak mengalami overfitting yang signifikan. Meskipun ada sedikit peningkatan pada validation loss di epoch kedua, penurunan kembali di epoch ketiga menunjukkan bahwa model dapat beradaptasi dan meningkatkan kemampuannya dalam mengklasifikasikan teks berita."],"metadata":{"id":"wTUHwkwCAm4a"}},{"cell_type":"code","source":["# Save the tokenizer\n","tokenizer.save_pretrained(output_dir)\n","print(f\"Tokenizer saved to {output_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1S1T7RV6m7jD","outputId":"d920ca4d-c601-443e-9585-9e08ac57898b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer saved to ./fine_tuned_bert_text_berita_clean_model\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Path to the fine-tuned model directory\n","model_directory = \"./fine_tuned_bert_text_berita_clean_model\"\n","\n","# Path to save the zip file\n","output_zip_path = \"fine_tuned_bert_model.zip\"\n","\n","# Zip the fine-tuned model directory\n","shutil.make_archive(\"fine_tuned_bert_model\", 'zip', model_directory)\n","\n","print(f\"Model successfully zipped to {output_zip_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FL0j5oiioNs","outputId":"0f0f9923-c97a-43a0-8b4e-bdf8dcc84bd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model successfully zipped to fine_tuned_bert_model.zip\n"]}]}]}